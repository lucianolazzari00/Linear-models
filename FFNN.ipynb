{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhuiED4uElu3YqTigyklF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucianolazzari00/Linear-models/blob/main/FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ecco l'implementazione della feed forwardd neural network con apprendimento tramite backpropagation.\n",
        "gli iper parametri sono:\n",
        "\n",
        "\n",
        "*   il numero di layer della rete (che possono essere settati modificanto la lista \"net_layers\")\n",
        "*   i numero di neuron per ogni layer (anche questi settabili modificando la lista \"net_layers\")\n",
        "\n",
        "\n",
        "*   il learning ratio\n",
        "\n",
        "il task assegnato era di fare regressinoe, dunque per le performance della NN ho arrotondato le previsioni all'intero piu vicino.\n",
        "\n",
        "ad esempio:\n",
        " se l'output del modello Ã¨ 1,77 allora arrotondo la previsione a 2\n",
        "\n"
      ],
      "metadata": {
        "id": "IkFzm3nSQVkq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNbiXutpOPpI",
        "outputId": "90124c93-212f-4c7b-826a-58156945413b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training the net...\n",
            "traning finished after 308 epochs\n",
            ">> ys predicted by the model (without rounding):  [ 0.    0.71  0.94  0.    1.71  1.15  1.85  0.01  0.03  2.02  1.18  0.\n",
            "  2.    0.98  1.28  0.01  0.99  1.4   0.02  0.02  1.31  1.48  1.41  0.01\n",
            "  1.8   1.04 -0.    0.    1.15  1.9 ]\n",
            ">> ys predicted by the model with rounding:  [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
            ">> ys expected from test data:  [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
            ">> Accuracy:  1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import math\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_der(z):\n",
        "    s = sigmoid(z)\n",
        "    return s*(1-s)\n",
        "\n",
        "class network():\n",
        "    def __init__(self, net_layers, learning_rate = 0.01,max_iterations=5000):\n",
        "        #creating the layers from user input\n",
        "        network_config = []\n",
        "        i=0\n",
        "        for i in range(len(net_layers)-2):\n",
        "            network_config.append(weighted_layer(net_layers[i],net_layers[i+1]))\n",
        "            network_config.append(activation_layer())\n",
        "        i+=1\n",
        "        network_config.append(weighted_layer(net_layers[i],net_layers[i+1]))\n",
        "\n",
        "        self.net_conf = network_config\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iterations = max_iterations\n",
        "\n",
        "    def predict(self,x):\n",
        "        y_pred = x \n",
        "        for layer in self.net_conf:\n",
        "            y_pred = layer.forward_prop(y_pred) \n",
        "        return y_pred\n",
        "\n",
        "    def train_function(self,samples,target):\n",
        "        print(\"training the net...\")\n",
        "        i=0\n",
        "        mse=100\n",
        "        while mse>0.03 and i<self.max_iterations:\n",
        "            i+=1\n",
        "            mse = 0\n",
        "            for sample_index in range(len(samples)):\n",
        "                s = samples[sample_index]\n",
        "                s = np.reshape(s,(len(s),1))\n",
        "                #forward\n",
        "                y_pred = self.predict(s)\n",
        "                y = target[sample_index]\n",
        "\n",
        "                #mean squared error\n",
        "                mse += np.mean(np.power(y-y_pred,2))\n",
        "                \n",
        "                #backprop\n",
        "                gradient = 2 * (y_pred-y) / np.size(y)\n",
        "                for layer in reversed(self.net_conf):\n",
        "                    gradient = layer.backward_prop(gradient,self.learning_rate)\n",
        "            mse = mse / len(samples)\n",
        "        print(\"traning finished after\", i , \"epochs\")\n",
        "        \n",
        "    def make_predictions(self,X_test):\n",
        "        y_pred = []\n",
        "        y_pred_cont = []\n",
        "        for sample in X_test:\n",
        "            sample = np.reshape(sample,(len(sample),1))\n",
        "            pred = self.predict(sample)\n",
        "            y_pred_cont.append(round(float(pred),2))\n",
        "            if pred < 0.5:\n",
        "                pred = 0\n",
        "            elif pred > 1.5:\n",
        "                pred = 2\n",
        "            else:\n",
        "                pred = 1\n",
        "            y_pred.append(int(pred))\n",
        "        return np.array(y_pred),np.array(y_pred_cont)\n",
        "\n",
        "class weighted_layer():\n",
        "    def __init__(self, neurons_input, neurons_output, X=None, Y=None):\n",
        "        self.X = X  #input vector\n",
        "        self.Y = Y  #output vector\n",
        "        self.W = np.random.randn(neurons_output,neurons_input) #weights matrix\n",
        "        self.b = np.random.randn(neurons_output,1)  #biases vector\n",
        "\n",
        "    def forward_prop(self,y_prev):\n",
        "        self.X = y_prev\n",
        "        return np.dot(self.W,self.X) + self.b\n",
        "\n",
        "    def backward_prop(self,grad_succ,learning_rate):  #sposta il lr globale\n",
        "        #backpropagation alg\n",
        "        w_gradient = np.dot(grad_succ,self.X.T)\n",
        "        grad_pred = np.dot(self.W.T,grad_succ)  #gradient to return to the previous layer\n",
        "        self.W = self.W - w_gradient * learning_rate  #update the weights\n",
        "        self.b = self.b - grad_succ * learning_rate #update the bias \n",
        "        return grad_pred\n",
        "\n",
        "\n",
        "class activation_layer():\n",
        "    #class to apply the activation function\n",
        "    def __init__(self, act_function = sigmoid, act_function_der=sigmoid_der, X=None, Y=None):\n",
        "        self.X = X  #input vector\n",
        "        self.Y = Y  #output vector\n",
        "        self.act_function = act_function \n",
        "        self.act_function_der = act_function_der #first derivative of act function\n",
        "    \n",
        "    def forward_prop(self, y_prev):\n",
        "        self.X = y_prev\n",
        "        return self.act_function(self.X)\n",
        "\n",
        "    def backward_prop(self, grad_succ, learning_rate):\n",
        "        return np.multiply(grad_succ, self.act_function_der(self.X))\n",
        "\n",
        "\n",
        "#split the data\n",
        "X,Y = data[\"data\"], data[\"target\"]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=1)\n",
        "\n",
        "#set the layers of the network\n",
        "net_layers = [4,5,7,3,1]\n",
        "neural_network = network(net_layers)\n",
        "\n",
        "#train the network\n",
        "neural_network.train_function(X_train,Y_train)\n",
        "\n",
        "#test\n",
        "Y_pred, pred_cont = neural_network.make_predictions(X_test)\n",
        "print(\">> ys predicted by the model (without rounding): \",pred_cont)\n",
        "print(\">> ys predicted by the model (with rounding): \",Y_pred)\n",
        "print(\">> ys expected from test data: \",Y_test)\n",
        "print(\">> Accuracy: \",accuracy_score(Y_test, Y_pred))    \n"
      ]
    }
  ]
}